{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59e5810-00e6-4c3c-b17e-51fc4b2e6adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de70e8-9d47-4af4-99fd-cd0a67a44ccd",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700240d7-7823-48ba-b43d-d37ee66f1f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# a.  Load CIFAR10 dataset into training and testing, features and labels numpy arrays using cifar10.load_data. \n",
    "\n",
    "(features_train, label_train), (features_test, label_test) = cifar10.load_data()\n",
    "print(np.unique(label_test))\n",
    "print(features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b0d3cfa-6f6a-4833-a4ec-25acf95e7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using markdown, list the 10 classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b4e90d-40ba-4bf6-9013-00c6d82acefd",
   "metadata": {},
   "source": [
    "The classes were found using the TensorFlow/Keras documentation for the CIFAR-10 dataset, and they are:\r\n",
    "\r\n",
    "0. Airplane  \r\n",
    "1. Automobile  \r\n",
    "2. Bird  \r\n",
    "3. Cat  \r\n",
    "4. Deer  \r\n",
    "5. Dog  \r\n",
    "6. Frog  \r\n",
    "7. Horse  \r\n",
    "8. Ship \r\n",
    "9. Truck\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb39f9c-e828-422f-a08b-698dc4fa8a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# b.  Create a bar plot using seaborn.barplot of the number of elements in each category of the entire dataset. \n",
    "\n",
    "unique_elements, counts = np.unique(label_test, return_counts=True)\n",
    "sns.barplot(x=unique_elements, y=counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Elements')\n",
    "plt.title('Number of Elements in Each Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee6b78a-06d5-4ee2-ad87-08d46f57c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use markdown to comment on how well balanced the dataset is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b24367b-f5cb-4b97-b0c7-80281b1c8d4a",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "The dataset appears to be well-balanced. Each class has approximately the same number of samples, which is ideal for training a classification model without bias toward any particular category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb5db4c-7ebc-4ca6-9a2e-d1c39a467a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_val length: 4000 \n",
      "x_test length: 6000\n"
     ]
    }
   ],
   "source": [
    "# c.  Use sklearn.model_selection.train_test_split to split the test set into test and validation sets choosing appropriate proportions. \n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(features_test, label_test, train_size=0.4, random_state=42)\n",
    "\n",
    "# Print length to ensure that the splitting worked, and test the scaled dataset to ensure the scaling of the features worked\n",
    "print(f'x_val length: {len(x_val)} \\nx_test length: {len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "624ceb77-cc60-4286-b145-c44354ee4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.  Create train, test, and validation data generators using tensorflow.keras.preprocessing.image.ImageDataGenerator; \n",
    "#     each should scale the data by dividing by 255, and the training generator should also use data augmentation. \n",
    "\n",
    "# Assign batch size of 32 to reduce computation power:\n",
    "batch_size = 32\n",
    "\n",
    "train_img_gen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "val_img_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_img_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_gen = train_img_gen.flow(features_train, label_train, batch_size=batch_size)\n",
    "val_data_gen = val_img_gen.flow(x_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d029cec0-8174-498f-add7-5dfc7fe0a651",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28fca2bc-c3eb-4e1b-906f-a396e9959911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 31, 31, 32)        416       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1568)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                100416    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105,610\n",
      "Trainable params: 105,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# a.  Use tf.keras.Sequential to create a convolutional neural network. Use at least two convolution layers and at least two pooling layers. \n",
    "#     Choose an activation function for each layer, and make sure the input and output dimensions are appropriate for the data. \n",
    "#     Print a summary of the model using tf.summary.\n",
    "\n",
    "# Assign dimentions for input_shape parameter:\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "\n",
    "model_CNN = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, 2, activation='relu', input_shape=(img_height, img_width ,3)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 2, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c9a6753-e57f-4c92-9c94-d2840d8ba054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b.  Compile the model with a choice of optimizer, sparse_categorical_crossentropy for the loss function, \n",
    "#     and set the metrics argument equal to ['accuracy'].\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "model_CNN.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cdb5afd-9b20-4e86-a5ae-909a4d545310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_26264\\2840077144.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_CNN.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1562/1562 [==============================] - 57s 36ms/step - loss: 1.6023 - accuracy: 0.0988 - val_loss: 1.3473 - val_accuracy: 0.0733\n",
      "Epoch 2/5\n",
      "1562/1562 [==============================] - 55s 35ms/step - loss: 1.3415 - accuracy: 0.0989 - val_loss: 1.2712 - val_accuracy: 0.1182\n",
      "Epoch 3/5\n",
      "1562/1562 [==============================] - 56s 36ms/step - loss: 1.2440 - accuracy: 0.0997 - val_loss: 1.1411 - val_accuracy: 0.0887\n",
      "Epoch 4/5\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 1.1733 - accuracy: 0.0999 - val_loss: 1.0461 - val_accuracy: 0.1035\n",
      "Epoch 5/5\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 1.1241 - accuracy: 0.0998 - val_loss: 1.0617 - val_accuracy: 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b5554e7160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c.  Train the model using the train and validation data generators; record the training accuracy. \n",
    "\n",
    "model_CNN.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=len(features_train) // batch_size,\n",
    "    epochs=5,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=len(y_val) // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "607e1167-d040-49f2-b477-26cebf0ee862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different architectures other hyperparameters to improve upon the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0b65052-d7a3-4492-931e-f502aca80957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Documentation of changes to hyperparameters:**\n",
    "\n",
    "\n",
    "# MODEL 0.5 - Complexity Introduction:\n",
    "\n",
    "# model_CNN = tf.keras.Sequential([\n",
    "#     layers.Conv2D(128, 2, activation='relu', input_shape=(img_height, img_width ,3)),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, 2, activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# Epoch 1/5\n",
    "# 1562/1562 [==============================] - 146s 93ms/step - loss: 1.5878 - accuracy: 0.0998 - val_loss: 1.3801 - val_accuracy: 0.0617\n",
    "# Epoch 2/5\n",
    "# 1562/1562 [==============================] - 139s 89ms/step - loss: 1.2704 - accuracy: 0.0972 - val_loss: 1.1116 - val_accuracy: 0.1029\n",
    "# Epoch 3/5\n",
    "# 1562/1562 [==============================] - 147s 94ms/step - loss: 1.1465 - accuracy: 0.1004 - val_loss: 1.0918 - val_accuracy: 0.1163\n",
    "# Epoch 4/5\n",
    "# 1562/1562 [==============================] - 144s 92ms/step - loss: 1.0732 - accuracy: 0.1005 - val_loss: 1.0668 - val_accuracy: 0.0949\n",
    "# Epoch 5/5\n",
    "# 1562/1562 [==============================] - 143s 91ms/step - loss: 1.0202 - accuracy: 0.1002 - val_loss: 0.9696 - val_accuracy: 0.1061\n",
    "\n",
    "\n",
    "# MODEL 1\n",
    "    \n",
    "# model = tf.keras.Sequential([\n",
    "#     layers.Conv2D(32, 2, activation='relu', input_shape=(img_height, img_width ,3)),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, 2, activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# Epoch 1/5\n",
    "# 1562/1562 [==============================] - 72s 46ms/step - loss: 1.5150 - accuracy: 0.1057 - val_loss: 1.3307 - val_accuracy: 0.1150\n",
    "# Epoch 2/5\n",
    "# 1562/1562 [==============================] - 71s 45ms/step - loss: 1.2140 - accuracy: 0.0995 - val_loss: 1.1531 - val_accuracy: 0.0961\n",
    "# Epoch 3/5\n",
    "# 1562/1562 [==============================] - 71s 45ms/step - loss: 1.1036 - accuracy: 0.1008 - val_loss: 1.0555 - val_accuracy: 0.1018\n",
    "# Epoch 4/5\n",
    "# 1562/1562 [==============================] - 71s 45ms/step - loss: 1.0256 - accuracy: 0.1015 - val_loss: 0.9984 - val_accuracy: 0.0991\n",
    "# Epoch 5/5\n",
    "# 1562/1562 [==============================] - 68s 44ms/step - loss: 0.9753 - accuracy: 0.1016 - val_loss: 0.9563 - val_accuracy: 0.0994\n",
    "\n",
    "# MODEL 2\n",
    "    \n",
    "# model = tf.keras.Sequential([\n",
    "#     layers.Conv2D(32, 2, activation='relu', input_shape=(img_height, img_width ,3)),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(32, 2, activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# Epoch 1/5r(\n",
    "# 1562/1562 [==============================] - 61s 39ms/step - loss: 1.6119 - accuracy: 0.0989 - val_loss: 1.4415 - val_accuracy: 0.0877\n",
    "# Epoch 2/5\n",
    "# 1562/1562 [==============================] - 63s 40ms/step - loss: 1.3252 - accuracy: 0.0956 - val_loss: 1.3024 - val_accuracy: 0.1380\n",
    "# Epoch 3/5\n",
    "# 1562/1562 [==============================] - 62s 40ms/step - loss: 1.2104 - accuracy: 0.0973 - val_loss: 1.1540 - val_accuracy: 0.0749\n",
    "# Epoch 4/5\n",
    "# 1562/1562 [==============================] - 60s 38ms/step - loss: 1.1431 - accuracy: 0.0989 - val_loss: 1.1506 - val_accuracy: 0.0832\n",
    "# Epoch 5/5\n",
    "# 1562/1562 [==============================] - 61s 39ms/step - loss: 1.0961 - accuracy: 0.0994 - val_loss: 1.0657 - val_accuracy: 0.1016\n",
    "\n",
    "\n",
    "# MODEL 3\n",
    "    \n",
    "# model = tf.keras.Sequential([\n",
    "#     layers.Conv2D(64, 2, activation='relu', input_shape=(img_height, img_width ,3)),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(32, 2, activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(32, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# Epoch 1/5r(\n",
    "# 1562/1562 [==============================] - 68s 43ms/step - loss: 1.6779 - accuracy: 0.1189 - val_loss: 1.4559 - val_accuracy: 0.1031\n",
    "# Epoch 2/5\n",
    "# 1562/1562 [==============================] - 68s 43ms/step - loss: 1.3861 - accuracy: 0.1005 - val_loss: 1.3018 - val_accuracy: 0.1397\n",
    "# Epoch 3/5\n",
    "# 1562/1562 [==============================] - 69s 44ms/step - loss: 1.2581 - accuracy: 0.0994 - val_loss: 1.2596 - val_accuracy: 0.0662\n",
    "# Epoch 4/5\n",
    "# 1562/1562 [==============================] - 68s 44ms/step - loss: 1.1905 - accuracy: 0.0998 - val_loss: 1.1560 - val_accuracy: 0.0907\n",
    "# Epoch 5/5\n",
    "# 1562/1562 [==============================] - 1209s 775ms/step - loss: 1.1348 - accuracy: 0.1021 - val_loss: 1.1257 - val_accuracy: 0.1118\n",
    "\n",
    "\n",
    "# MODEL 4 -Dropout implemented\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     layers.Conv2D(64, 2, activation='relu', input_shape=(img_height, img_width ,3)),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Conv2D(32, 2, activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(32, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# Epoch 1/5r(\n",
    "# 1562/1562 [==============================] - 77s 49ms/step - loss: 1.8158 - accuracy: 0.1470 - val_loss: 1.5688 - val_accuracy: 0.0963\n",
    "# Epoch 2/5\n",
    "# 1562/1562 [==============================] - 72s 46ms/step - loss: 1.5055 - accuracy: 0.0993 - val_loss: 1.3672 - val_accuracy: 0.0541\n",
    "# Epoch 3/5\n",
    "# 1562/1562 [==============================] - 71s 46ms/step - loss: 1.3872 - accuracy: 0.0961 - val_loss: 1.2835 - val_accuracy: 0.0595\n",
    "# Epoch 4/5\n",
    "# 1562/1562 [==============================] - 73s 47ms/step - loss: 1.3094 - accuracy: 0.0962 - val_loss: 1.2784 - val_accuracy: 0.0645\n",
    "# Epoch 5/5\n",
    "# 1562/1562 [==============================] - 72s 46ms/step - loss: 1.2630 - accuracy: 0.0963 - val_loss: 1.1721 - val_accuracy: 0.0814"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c7240-b76c-41aa-9ecd-534b8d2c3385",
   "metadata": {},
   "source": [
    "# 2. Modeling - Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01de8f75-1ae3-4161-a857-bc97081f1d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnetb0\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 224, 224, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " normalization (Normalization)  (None, 224, 224, 3)  7           ['rescaling[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 224, 224, 3)  0           ['normalization[0][0]']          \n",
      "                                                                                                  \n",
      " stem_conv_pad (ZeroPadding2D)  (None, 225, 225, 3)  0           ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['stem_conv_pad[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_activation (Activation)   (None, 112, 112, 32  0           ['stem_bn[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['stem_activation[0][0]']        \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1a_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_activation (Activation  (None, 112, 112, 32  0          ['block1a_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1a_activation[0][0]',     \n",
      "                                )                                 'block1a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 16  512         ['block1a_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 16  64         ['block1a_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 96  1536        ['block1a_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 96  384        ['block2a_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_activation (Act  (None, 112, 112, 96  0          ['block2a_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_dwconv_pad (ZeroPaddin  (None, 113, 113, 96  0          ['block2a_expand_activation[0][0]\n",
      " g2D)                           )                                ']                               \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 96)  864         ['block2a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 96)  384         ['block2a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_activation (Activation  (None, 56, 56, 96)  0           ['block2a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 96)   0           ['block2a_activation[0][0]',     \n",
      "                                                                  'block2a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 24)   2304        ['block2a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block2b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_expand_activation (Act  (None, 56, 56, 144)  0          ['block2b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 144)  1296       ['block2b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 144)  576        ['block2b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_activation (Activation  (None, 56, 56, 144)  0          ['block2b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 144)  0           ['block2b_activation[0][0]',     \n",
      "                                                                  'block2b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 24)   3456        ['block2b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)         (None, 56, 56, 24)   0           ['block2b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_add (Add)              (None, 56, 56, 24)   0           ['block2b_drop[0][0]',           \n",
      "                                                                  'block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block3a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_expand_activation (Act  (None, 56, 56, 144)  0          ['block3a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_dwconv_pad (ZeroPaddin  (None, 59, 59, 144)  0          ['block3a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 144)  576        ['block3a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_activation (Activation  (None, 28, 28, 144)  0          ['block3a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 144)  0           ['block3a_activation[0][0]',     \n",
      "                                                                  'block3a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 40)   5760        ['block3a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block3b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_expand_activation (Act  (None, 28, 28, 240)  0          ['block3b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 240)  6000       ['block3b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 240)  960        ['block3b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_activation (Activation  (None, 28, 28, 240)  0          ['block3b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 240)  0           ['block3b_activation[0][0]',     \n",
      "                                                                  'block3b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 40)   9600        ['block3b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)         (None, 28, 28, 40)   0           ['block3b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_add (Add)              (None, 28, 28, 40)   0           ['block3b_drop[0][0]',           \n",
      "                                                                  'block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block4a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_expand_activation (Act  (None, 28, 28, 240)  0          ['block4a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_dwconv_pad (ZeroPaddin  (None, 29, 29, 240)  0          ['block4a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 240)  960        ['block4a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_activation (Activation  (None, 14, 14, 240)  0          ['block4a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 240)  0           ['block4a_activation[0][0]',     \n",
      "                                                                  'block4a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 80)   19200       ['block4a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_expand_activation (Act  (None, 14, 14, 480)  0          ['block4b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_activation (Activation  (None, 14, 14, 480)  0          ['block4b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4b_activation[0][0]',     \n",
      "                                                                  'block4b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)         (None, 14, 14, 80)   0           ['block4b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_add (Add)              (None, 14, 14, 80)   0           ['block4b_drop[0][0]',           \n",
      "                                                                  'block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_expand_activation (Act  (None, 14, 14, 480)  0          ['block4c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_activation (Activation  (None, 14, 14, 480)  0          ['block4c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4c_activation[0][0]',     \n",
      "                                                                  'block4c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)         (None, 14, 14, 80)   0           ['block4c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_add (Add)              (None, 14, 14, 80)   0           ['block4c_drop[0][0]',           \n",
      "                                                                  'block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_expand_activation (Act  (None, 14, 14, 480)  0          ['block5a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  12000      ['block5a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block5a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_activation (Activation  (None, 14, 14, 480)  0          ['block5a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block5a_activation[0][0]',     \n",
      "                                                                  'block5a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 112)  53760       ['block5a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_expand_activation (Act  (None, 14, 14, 672)  0          ['block5b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_activation (Activation  (None, 14, 14, 672)  0          ['block5b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5b_activation[0][0]',     \n",
      "                                                                  'block5b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)         (None, 14, 14, 112)  0           ['block5b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_add (Add)              (None, 14, 14, 112)  0           ['block5b_drop[0][0]',           \n",
      "                                                                  'block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_expand_activation (Act  (None, 14, 14, 672)  0          ['block5c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_activation (Activation  (None, 14, 14, 672)  0          ['block5c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5c_activation[0][0]',     \n",
      "                                                                  'block5c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)         (None, 14, 14, 112)  0           ['block5c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_add (Add)              (None, 14, 14, 112)  0           ['block5c_drop[0][0]',           \n",
      "                                                                  'block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_expand_activation (Act  (None, 14, 14, 672)  0          ['block6a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_dwconv_pad (ZeroPaddin  (None, 17, 17, 672)  0          ['block6a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 672)   2688        ['block6a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_activation (Activation  (None, 7, 7, 672)   0           ['block6a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 672)    0           ['block6a_activation[0][0]',     \n",
      "                                                                  'block6a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 192)    129024      ['block6a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_activation (Activation  (None, 7, 7, 1152)  0           ['block6b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6b_activation[0][0]',     \n",
      "                                                                  'block6b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)         (None, 7, 7, 192)    0           ['block6b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_add (Add)              (None, 7, 7, 192)    0           ['block6b_drop[0][0]',           \n",
      "                                                                  'block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_activation (Activation  (None, 7, 7, 1152)  0           ['block6c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6c_activation[0][0]',     \n",
      "                                                                  'block6c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)         (None, 7, 7, 192)    0           ['block6c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_add (Add)              (None, 7, 7, 192)    0           ['block6c_drop[0][0]',           \n",
      "                                                                  'block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_activation (Activation  (None, 7, 7, 1152)  0           ['block6d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6d_activation[0][0]',     \n",
      "                                                                  'block6d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)         (None, 7, 7, 192)    0           ['block6d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_add (Add)              (None, 7, 7, 192)    0           ['block6d_drop[0][0]',           \n",
      "                                                                  'block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_expand_activation (Act  (None, 7, 7, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  10368       ['block7a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_activation (Activation  (None, 7, 7, 1152)  0           ['block7a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block7a_activation[0][0]',     \n",
      "                                                                  'block7a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 320)    368640      ['block7a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 320)   1280        ['block7a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)              (None, 7, 7, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 1280)   5120        ['top_conv[0][0]']               \n",
      "                                                                                                  \n",
      " top_activation (Activation)    (None, 7, 7, 1280)   0           ['top_bn[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,049,571\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4,049,571\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# d.  Start a new model by loading one of the models from tensorflow.keras.applications along with the pretrained weights; don't include the top layer. \n",
    "#     Check if your model comes with preprocess_input function and be sure to use that properly with your data before training.\n",
    "\n",
    "# Assign channel along with dimensions tailored to the model:\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "channel = 3\n",
    "\n",
    "# Use preprocess_input in ImageDataGenerator\n",
    "train_img_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_data_gen = train_img_gen.flow(features_train, label_train, batch_size=batch_size)\n",
    "\n",
    "val_img_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_data_gen = val_img_gen.flow(x_val, y_val, batch_size=batch_size)\n",
    "\n",
    "test_img_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_data_gen = test_img_gen.flow(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "base_model = EfficientNetB0(input_shape=(img_height, img_width, channel), weights='imagenet', include_top=False)\n",
    "base_model.trainable =  False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ce935c5-296e-4af6-8c53-aba723775de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the model you chose using markdown and explain why you think it will work well for this use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b299821d-72e4-47e8-a251-1c251d666d97",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "I decided to use the EfficientNetB0 model because after some research, I found that this model is small and fast, and offers a strong balance between efficiency and accuracy without utilizing a lot of computational power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fe53497-49ab-4859-a814-18294cbd66cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                40992     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,090,893\n",
      "Trainable params: 41,322\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# e.  Add on a new top layer with appropriate hyperparameter choices. Choose a number of layers to freeze. Print a summary of the model.\n",
    "\n",
    "model_tl = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),   # Replace Flatten() with model specific function\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_tl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db8eb74c-27cf-4323-b981-325af420a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.  Compile the model with a choice of optimizer and loss function, and the set the metrics argument equal to ['accuracy'].\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "model_tl.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e985788-5539-4951-a2a7-9b1c63231e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_26264\\1716660229.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_tl.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - 86s 50ms/step - loss: 1.5453 - accuracy: 0.0964 - val_loss: 1.3478 - val_accuracy: 0.0632\n",
      "Epoch 2/5\n",
      "1562/1562 [==============================] - 82s 52ms/step - loss: 1.3171 - accuracy: 0.0946 - val_loss: 1.2466 - val_accuracy: 0.1053\n",
      "Epoch 3/5\n",
      "1562/1562 [==============================] - 82s 53ms/step - loss: 1.2578 - accuracy: 0.0957 - val_loss: 1.2256 - val_accuracy: 0.0602\n",
      "Epoch 4/5\n",
      "1562/1562 [==============================] - 79s 51ms/step - loss: 1.2251 - accuracy: 0.0969 - val_loss: 1.1830 - val_accuracy: 0.0860\n",
      "Epoch 5/5\n",
      "1562/1562 [==============================] - 83s 53ms/step - loss: 1.1980 - accuracy: 0.0983 - val_loss: 1.1648 - val_accuracy: 0.1343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b5480abd60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g.  Train the model using the train and validation data generators; record the training accuracy. \n",
    "\n",
    "model_tl.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=len(features_train) // batch_size,\n",
    "    epochs=5,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=len(y_val) // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81291e23-7662-4a7a-84db-c89a711e33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different architectures, different numbers of frozen layers, and other hyperparameters to improve upon the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a13da90c-85ec-49e0-8569-4e65c51a48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Documentation of changes to hyperparameters:**\n",
    "\n",
    "# MODEL 1\n",
    "    \n",
    "# model = tf.keras.Sequential([\n",
    "#     base_model,\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# Epoch 1/5or(\n",
    "# 1562/1562 [==============================] - 83s 53ms/step - loss: 1.1477 - accuracy: 0.1011 - val_loss: 1.1621 - val_accuracy: 0.0967\n",
    "# Epoch 2/5\n",
    "# 1562/1562 [==============================] - 83s 53ms/step - loss: 1.1283 - accuracy: 0.1013 - val_loss: 1.1328 - val_accuracy: 0.0900\n",
    "# Epoch 3/5\n",
    "# 1562/1562 [==============================] - 78s 50ms/step - loss: 1.1194 - accuracy: 0.1012 - val_loss: 1.2028 - val_accuracy: 0.1405\n",
    "# Epoch 4/5\n",
    "# 1562/1562 [==============================] - 77s 49ms/step - loss: 1.1024 - accuracy: 0.1016 - val_loss: 1.1160 - val_accuracy: 0.1100\n",
    "# Epoch 5/5\n",
    "# 1562/1562 [==============================] - 78s 50ms/step - loss: 1.0897 - accuracy: 0.1019 - val_loss: 1.1331 - val_accuracy: 0.0915\n",
    "\n",
    "\n",
    "# MODEL 2\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     base_model,\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(32, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# Epoch 1/5r(\n",
    "# 1562/1562 [==============================] - 87s 51ms/step - loss: 1.4822 - accuracy: 0.0861 - val_loss: 1.3108 - val_accuracy: 0.0993\n",
    "# Epoch 2/5\n",
    "# 1562/1562 [==============================] - 78s 50ms/step - loss: 1.2812 - accuracy: 0.0974 - val_loss: 1.2903 - val_accuracy: 0.0780\n",
    "# Epoch 3/5\n",
    "# 1562/1562 [==============================] - 78s 50ms/step - loss: 1.2315 - accuracy: 0.0979 - val_loss: 1.1999 - val_accuracy: 0.0988\n",
    "# Epoch 4/5\n",
    "# 1562/1562 [==============================] - 78s 50ms/step - loss: 1.2029 - accuracy: 0.0987 - val_loss: 1.1751 - val_accuracy: 0.0868\n",
    "# Epoch 5/5\n",
    "# 1562/1562 [==============================] - 78s 50ms/step - loss: 1.1846 - accuracy: 0.0988 - val_loss: 0.1601 - val_accuracy: 0.1088\n",
    "\n",
    "\n",
    "# MODEL 3 - Unfreezing 20 layers of best model above ^\n",
    "    \n",
    "# #Freeze all layers except the last 20\n",
    "# for layer in base_model.layers[:-20]:\n",
    "#     layer.trainable = False\n",
    "# for layer in base_model.layers[-20:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     base_model,\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(32, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# Epoch 1/5r(\n",
    "# 1562/1562 [==============================] - 107s 63ms/step - loss: 1.3165 - accuracy: 0.1050 - val_loss: 1.1161 - val_accuracy: 0.0775\n",
    "# Epoch 2/5\n",
    "# 1562/1562 [==============================] - 97s 62ms/step - loss: 1.1102 - accuracy: 0.1039 - val_loss: 1.0579 - val_accuracy: 0.1082\n",
    "# Epoch 3/5\n",
    "# 1562/1562 [==============================] - 96s 62ms/step - loss: 1.0308 - accuracy: 0.1012 - val_loss: 1.0160 - val_accuracy: 0.0948\n",
    "# Epoch 4/5\n",
    "# 1562/1562 [==============================] - 97s 62ms/step - loss: 0.9691 - accuracy: 0.0998 - val_loss: 0.9841 - val_accuracy: 0.0927\n",
    "# Epoch 5/5\n",
    "# 1562/1562 [==============================] - 96s 61ms/step - loss: 0.9225 - accuracy: 0.1019 - val_loss: 1.0160 - val_accuracy: 0.1420\n",
    "\n",
    "\n",
    "# MODEL 4 - Unfreezing 10 layers of the best model before\n",
    "\n",
    "# #Freeze all layers except the last 10\n",
    "# for layer in base_model.layers[:-10]:\n",
    "#     layer.trainable = False\n",
    "# for layer in base_model.layers[-10:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# Epoch 1/5r(\n",
    "# 1562/1562 [==============================] - 107s 63ms/step - loss: 1.2893 - accuracy: 0.1008 - val_loss: 1.1779 - val_accuracy: 0.1040\n",
    "# Epoch 2/5\n",
    "# 1562/1562 [==============================] - 94s 60ms/step - loss: 1.0928 - accuracy: 0.1011 - val_loss: 1.0616 - val_accuracy: 0.0990\n",
    "# Epoch 3/5\n",
    "# 1562/1562 [==============================] - 94s 60ms/step - loss: 1.0311 - accuracy: 0.1023 - val_loss: 1.0285 - val_accuracy: 0.0960\n",
    "# Epoch 4/5\n",
    "# 1562/1562 [==============================] - 95s 61ms/step - loss: 0.9765 - accuracy: 0.1015 - val_loss: 1.0135 - val_accuracy: 0.0995\n",
    "# Epoch 5/5\n",
    "# 1562/1562 [==============================] - 93s 60ms/step - loss: 0.9281 - accuracy: 0.1028 - val_loss: 1.0403 - val_accuracy: 0.1123\n",
    "\n",
    "# MODEL 5 - Unfreezing 30 layers\n",
    "\n",
    "# #Freeze all layers except the last 30\n",
    "# for layer in base_model.layers[:-30]:\n",
    "#     layer.trainable = False\n",
    "# for layer in base_model.layers[-30:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# Epoch 1/5r(\n",
    "# 1562/1562 [==============================] - 110s 65ms/step - loss: 1.3219 - accuracy: 0.1042 - val_loss: 1.0976 - val_accuracy: 0.1128\n",
    "# Epoch 2/5\n",
    "# 1562/1562 [==============================] - 103s 66ms/step - loss: 1.1137 - accuracy: 0.1031 - val_loss: 1.0213 - val_accuracy: 0.1130\n",
    "# Epoch 3/5\n",
    "# 1562/1562 [==============================] - 102s 65ms/step - loss: 1.0334 - accuracy: 0.1024 - val_loss: 1.0087 - val_accuracy: 0.1070\n",
    "# Epoch 4/5\n",
    "# 1562/1562 [==============================] - 104s 66ms/step - loss: 0.9759 - accuracy: 0.1024 - val_loss: 0.9961 - val_accuracy: 0.1088\n",
    "# Epoch 5/5\n",
    "# 1562/1562 [==============================] - 102s 65ms/step - loss: 0.9259 - accuracy: 0.1088 - val_loss: 0.1420 - val_accuracy: 0.0915"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfac506-20bc-490f-a92e-58661b5cd1ad",
   "metadata": {},
   "source": [
    "# 3. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c24b6461-a8a0-4d99-8881-42fd196b621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 11s 7ms/step\n",
      "125/125 [==============================] - 1s 7ms/step\n",
      "1563/1563 [==============================] - 74s 46ms/step\n",
      "125/125 [==============================] - 6s 47ms/step\n",
      "Custom CNN Model Accuracies:\n",
      "Training Accuracy: 0.10042 \n",
      " Validation Accuracy: 0.1005\n",
      "Transfer Learning Model Accuracies:\n",
      "Training Accuracy: 0.099 \n",
      " Validation Accuracy: 0.10725\n",
      "Custom Model Confusion Matrix:\n",
      "[[100  92   3  45   0  10   2  41  78  40]\n",
      " [ 99  97   2  29   0  12   4  36  85  45]\n",
      " [102  73   1  39   0  10   3  40  66  40]\n",
      " [100  92   0  37   1  13   0  40  65  57]\n",
      " [ 89 106   2  38   0   8   4  34  73  42]\n",
      " [103  91   1  49   0  11   4  43  71  50]\n",
      " [ 87 105   1  17   2  12   4  41  78  52]\n",
      " [ 92  84   1  38   0  10   4  40  65  42]\n",
      " [101  94   2  34   3  14   4  43  75  38]\n",
      " [114  83   1  37   4   8   3  40  72  37]]\n",
      "Transfer Learning Model Confusion Matrix:\n",
      "[[46 36 31 31 45 51 46 49 40 36]\n",
      " [62 63 25 31 22 42 46 28 42 48]\n",
      " [55 28 25 19 38 33 41 41 42 52]\n",
      " [65 28 25 23 35 48 52 34 52 43]\n",
      " [49 40 23 29 42 49 53 35 41 35]\n",
      " [61 29 27 29 33 50 49 55 42 48]\n",
      " [49 40 31 18 29 41 54 45 46 46]\n",
      " [40 31 30 24 39 46 52 36 44 34]\n",
      " [55 38 34 33 38 43 42 46 41 38]\n",
      " [55 32 29 27 20 44 49 46 48 49]]\n"
     ]
    }
   ],
   "source": [
    "# a.  Find the training and validation accuracies, and validation confusion matrix for both the custom CNN and transfer learning models. \n",
    "#     Present the results for both neatly.\n",
    "\n",
    "# Get predictions on sets with custom CNN best model:\n",
    "train_preds_CNN = model_CNN.predict(train_data_gen)\n",
    "train_true_CNN = label_train[: len(train_preds_CNN)]  # align lengths\n",
    "train_pred_CNN = np.argmax(train_preds_CNN, axis=1)\n",
    "\n",
    "val_preds_CNN = model_CNN.predict(val_data_gen)\n",
    "val_true_CNN = y_val[: len(val_preds_CNN)]  # align lengths\n",
    "val_pred_CNN = np.argmax(val_preds_CNN, axis=1)\n",
    "\n",
    "# Get predictions on sets with transfer learning best model:\n",
    "train_preds_tl = model_tl.predict(train_data_gen)\n",
    "train_true_tl = label_train[: len(train_preds_tl)]  # align lengths\n",
    "train_pred_tl = np.argmax(train_preds_tl, axis=1)\n",
    "\n",
    "val_preds_tl = model_tl.predict(val_data_gen)\n",
    "val_true_tl = y_val[: len(val_preds_tl)]  # align lengths\n",
    "val_pred_tl = np.argmax(val_preds_tl, axis=1)\n",
    "\n",
    "print(\"Custom CNN Model Accuracies:\")\n",
    "print(f'Training Accuracy: {accuracy_score(train_true_CNN, train_pred_CNN)} \\n Validation Accuracy: {accuracy_score(val_true_CNN, val_pred_CNN)}')\n",
    "print(\"Transfer Learning Model Accuracies:\")\n",
    "print(f'Training Accuracy: {accuracy_score(train_true_tl, train_pred_tl)} \\n Validation Accuracy: {accuracy_score(val_true_tl, val_pred_tl)}')\n",
    "\n",
    "print(\"Custom Model Confusion Matrix:\")\n",
    "print(confusion_matrix(val_true_CNN, val_pred_CNN))\n",
    "print(\"Transfer Learning Model Confusion Matrix:\")\n",
    "print(confusion_matrix(val_true_tl, val_pred_tl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d231c913-92a5-404c-8c9e-7e5d090127cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use markdown to compare them and select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ae079-509a-476d-a2f1-343c17972794",
   "metadata": {},
   "source": [
    "### Final Model Evaluation & Explanation\n",
    "\n",
    "After experimenting with multiple architectures, I selected the best-performing models from both the custom CNN group and the transfer learning group. Below is a breakdown of why each model stood out, followed by my final selection.\n",
    "\n",
    "---\n",
    "\n",
    "#### Custom CNN  Model 3\n",
    "<pre>\n",
    "Model architecture:\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(64, 2, activation='relu', input_shape=(img_height, img_width ,3)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 2, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "</pre>\n",
    "Training Summary:\n",
    "- Training Accuracy: 0.1004\n",
    "- Validation Accuracy: 0.1005\n",
    "- Final Loss: 1.1348\n",
    "- Validation Loss: 1.1257\n",
    "\n",
    "This model showed the highest accuracy among the custom CNNs and maintained a relatively low error rate. While the accuracy plateaued early, it didnt show signs of severe overfitting. The architecture was simple yet effective, and the training time was manageable.\n",
    "\n",
    "---\n",
    "\n",
    "#### Transfer Learning  Model 2\n",
    "<pre>\n",
    "Model architecture:\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "</pre>\n",
    "Training Summary:\n",
    "- Training Accuracy: 0.099\n",
    "- Validation Accuracy: 0.1073\n",
    "- Final Loss: 1.1846\n",
    "- Validation Loss: 1.1601\n",
    "\n",
    "This model leveraged pretrained weights from EfficientNetB0 and achieved the highest validation accuracy overall. It showed no clear signs of overfitting and required less architectural tuning. While the training accuracy was slightly lower than the custom model, the validation performance was more consistent.\n",
    "\n",
    "---\n",
    "\n",
    "### Confusion Matrix Comparison\n",
    "\n",
    "- Custom CNN misclassified 3,708 samples.\n",
    "- Transfer Learning Model misclassified 3,681 samples.\n",
    "- Difference: 27 fewer errors in favor of the transfer learning model.\n",
    "\n",
    "This reinforces the transfer models ability to generalize better, even with minimal fine-tuning.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Verdict\n",
    "\n",
    "Despite the custom CNN showing slightly higher training accuracy, I selected Transfer Learning Model 2 as the best overall. It offered:\n",
    "\n",
    "- Higher validation accuracy\n",
    "- Lower validation loss\n",
    "- Fewer misclassifications\n",
    "- Better generalization\n",
    "- Efficient use of pretrained features\n",
    "\n",
    "Additionally, the model required less computational power and fewer architectural changes, making it more practical for real-world deployment.\n",
    "\n",
    "---\n",
    "\n",
    "### Potential Improvements (Not Implemented)\n",
    "\n",
    "To address overfitting or improve performance, I considered:\n",
    "- Increasing stride or kernel size to reduce complexity\n",
    "- Experimenting with pooling methods or dense layer configurations\n",
    "- Applying regularization techniques like dropout or batch normalization\n",
    "\n",
    "However, due to the high computational cost (nearly a minute per epoch), I chose not to pursue these iterations.\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset Limitations\n",
    "\n",
    "I believe the low accuracy across models is largely due to the CIFAR-10 dataset itself. Its small image size and class overlap make it difficult for models to learn distinct features. In previous exercises, even well-tuned models struggled to exceed 0.1012 accuracy, often overfitting early.\n",
    "\n",
    "To improve results, additional preprocessing (e.g., data cleaning, augmentation, or class balancing) would be necessary before model development. Exploring alternative architectures or training on higher-resolution datasets could also help, but would require significantly more resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "809d8f97-eb07-4fa3-9824-1d5a8a30de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 9s 47ms/step\n",
      "Test Accuracy: 0.1045 \n",
      "\n",
      "[[92 40 41 37 47 62 67 75 61 67]\n",
      " [81 45 49 49 52 72 78 52 53 60]\n",
      " [85 42 41 52 51 81 81 69 68 56]\n",
      " [76 76 37 40 44 63 70 61 59 69]\n",
      " [83 71 39 43 40 71 59 73 71 54]\n",
      " [66 52 39 45 51 73 74 69 57 51]\n",
      " [82 60 44 47 42 60 84 67 67 48]\n",
      " [78 55 32 61 50 65 73 81 71 58]\n",
      " [63 63 32 48 60 62 74 59 61 70]\n",
      " [77 49 38 46 69 58 61 65 68 70]]\n"
     ]
    }
   ],
   "source": [
    "# b.  Find the testing accuracy and confusion matrix of only the best model.\n",
    "\n",
    "# Get predictions on validation set\n",
    "test_preds = model_tl.predict(test_data_gen)\n",
    "test_labels_true = y_test[: len(test_preds)]  # align lengths\n",
    "test_labels_pred = np.argmax(test_preds, axis=1)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy_score(test_labels_true, test_labels_pred)} \\n')\n",
    "print(confusion_matrix(test_labels_true, test_labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e905cd6-7a99-4d50-b45c-667d952cec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n",
      "Cat with backgroud noise.jpg  0 \n",
      " -> [[0.5478789  0.04312315 0.10085101 0.1999445  0.02904491 0.01767058\n",
      "  0.02472136 0.02225019 0.00873766 0.00577782]]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "clear cat image.jpg  3 \n",
      " -> [[0.10918576 0.00425079 0.07192776 0.3559012  0.03413737 0.18983395\n",
      "  0.00641528 0.21998958 0.00453825 0.0038201 ]]\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "upside down cat.jpg  7 \n",
      " -> [[0.10813107 0.02383498 0.04884055 0.21940194 0.14296125 0.16115707\n",
      "  0.02296782 0.26829115 0.00064406 0.00377013]]\n"
     ]
    }
   ],
   "source": [
    "# c.  Use the model to make predictions on at least three other images from one of the 10 classes.\n",
    "\n",
    "for img_path in ['Cat with backgroud noise.jpg','clear cat image.jpg','upside down cat.jpg']:\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    x   = image.img_to_array(img)\n",
    "    x   = np.expand_dims(x, axis=0)\n",
    "    x   = preprocess_input(x)\n",
    "    \n",
    "    pred = model_tl.predict(x)\n",
    "    print(f\"{img_path}  {np.argmax(pred)} \\n -> {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c917e3-74b3-4e37-be53-5c1507055a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.  Use markdown to comment on how well the model works to make predictions for this use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d8bd1-1a87-411f-968c-f4185f20db79",
   "metadata": {},
   "source": [
    "### Final Evaluation: Model Performance on Real-World Images\n",
    "\n",
    "The final test accuracy for the selected transfer learning model was **10.45%**, which is consistent with the validation performance observed during training. While this accuracy is low, it reflects the inherent difficulty of the CIFAR-10 dataset  particularly its small image size and overlapping visual features across classes.\n",
    "\n",
    "The test confusion matrix shows that the model struggled to distinguish between many of the classes, with predictions spread widely across categories. For example, the model frequently confused cats with dogs, horses, and even airplanes, which is evident in the real-world image predictions:\n",
    "\n",
    "- **Cat with background noise.jpg** was classified as **airplane (class 0)** with 54.8% confidence.\n",
    "- **Clear cat image.jpg** was correctly classified as **cat (class 3)**, but only with 35.6% confidence.\n",
    "- **Upside down cat.jpg** was classified as **horse (class 7)** with 26.8% confidence.\n",
    "\n",
    "These results suggest that while the model can sometimes identify the correct class, it lacks robustness when faced with real-world variations such as background clutter, orientation changes, or lighting differences.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- The model performs reasonably well on clean, centered images but struggles with noisy or unconventional inputs.\n",
    "- The low confidence scores and frequent misclassifications highlight the need for further training, better data preprocessing, or more advanced architectures.\n",
    "- For practical deployment, additional steps such as fine-tuning, data augmentation, or using higher-resolution datasets would be necessary to improve reliability.\n",
    "\n",
    "Overall, the model demonstrates basic classification capability but is not yet suitable for real-world decision-making without further refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58561e2f-2272-4b8b-9b44-79de51efb88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
