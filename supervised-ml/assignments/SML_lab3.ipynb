{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c7af504-2f8a-44b7-bbd2-0658de5fc703",
   "metadata": {},
   "source": [
    "# SML Lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f59083-079a-4079-a95e-a6caca4b37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import turicreate as tc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab383c6-22fd-400d-b1c5-78fe8731cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) In a markdown cell, discuss whether a false positive or false negative is \n",
    "# worse for this use case. State a value of Œ≤ that is suitable for an FŒ≤ score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b872e-328e-41ed-b267-d54d3dd72fe5",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "1. A false negative (FN) is worse than a false positive (FP). With a FP, maintenance staff might be alerted to a failure that doesn‚Äôt exist, resulting in an unnecessary inspection. However, with an FN, a failure is missed, potentially leading to serious consequences such as safety issues, equipment malfunction, or even catastrophic failure.\n",
    "\n",
    "2. A suitable value for Œ≤ in the FŒ≤ score is 2. This value is greater than 1, which means it prioritizes recall over precision, focusing more on minimizing false negatives. Given that false negatives are more critical in this context, using Œ≤ = 2 helps ensure that actual failures are detected and addressed promptly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85839365-35b6-4a97-9f34-de0281bf3088",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/mgalinsky/SML/Lab3/0399259_data.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/mgalinsky/SML/Lab3/0399259_data.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,float,float,float]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.036817 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.036817 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/mgalinsky/SML/Lab3/0399259_data.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/mgalinsky/SML/Lab3/0399259_data.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1000 lines in 0.012065 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1000 lines in 0.012065 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------+\n",
      "| Condition |      Voltage       |      Current       |    Temperature     |\n",
      "+-----------+--------------------+--------------------+--------------------+\n",
      "|     0     | 12.105402229028574 | 1.2010158804571862 | 27.021383826347545 |\n",
      "|     0     | 18.47696101766036  | 9.228798007868006  | 19.223667320653277 |\n",
      "|     0     | 5.699595016939316  | 31.970087490684595 | 26.006400351846032 |\n",
      "|     0     | 32.26151306174472  | 13.278921807347974 | 83.45379653646954  |\n",
      "|     0     | 17.214851542698558 | 10.747552975112113 | 29.968236276473505 |\n",
      "|     0     | 11.509978758782651 | 13.364409126220089 | 29.776983373817707 |\n",
      "|     0     | 25.21192122391736  | 16.613095269745283 | 34.362140439076796 |\n",
      "|     0     | 27.07633338214532  | 10.639192625540735 | 48.82253332157811  |\n",
      "|     0     | 26.55653370361028  | 5.011417360921026  | 29.52311270140705  |\n",
      "|     0     | 27.626069846362416 | 14.52428111164478  | 47.07836152351818  |\n",
      "+-----------+--------------------+--------------------+--------------------+\n",
      "[1000 rows x 4 columns]\n",
      "Note: Only the head of the SFrame is printed.\n",
      "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n"
     ]
    }
   ],
   "source": [
    "# 2) Load the CSV file into an SFrame named data. Print the SFrame. \n",
    "# Split the data into training/validation/testing sets using 80%/10%/10% respectively.\n",
    "\n",
    "data = tc.SFrame('0399259_data.csv')\n",
    "print(data)\n",
    "\n",
    "voltage = np.array(data['Voltage'])\n",
    "current = np.array(data['Current'])\n",
    "temp = np.array(data['Temperature'])\n",
    "condition = np.array(data['Condition'])\n",
    "features = np.column_stack((voltage, current, temp))\n",
    "\n",
    "x_train, x_valtest, y_train, y_valtest = train_test_split(features, condition, train_size=0.8)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_valtest, y_valtest, train_size=0.5)\n",
    "\n",
    "train_data = tc.SFrame({'Voltage': x_train[:, 0], 'Current': x_train[:, 1], 'Temperature': x_train[:, 2], 'Condition': y_train})\n",
    "val_data = tc.SFrame({'Voltage': x_val[:, 0], 'Current': x_val[:, 1], 'Temperature': x_val[:, 2], 'Condition': y_val})\n",
    "test_data = tc.SFrame({'Voltage': x_test[:, 0], 'Current': x_test[:, 1], 'Temperature': x_test[:, 2], 'Condition': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd90161-4e53-4d0d-aab3-4ee826dd67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Note in markdown whether or not feature rescaling is turned on by default \n",
    "# for the function turicreate.logistic_classifier.create, and state which \n",
    "# scale (original or rescaled) the coefficients are given in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd1f90-da67-4619-a552-2ceed5ea47f8",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "1. By default, feature rescaling is turned on for this function.\n",
    "2. The coefficients provided are based on the rescaled features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bced7f80-89b8-41b1-bc71-bb54fea6d05e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 760</pre>"
      ],
      "text/plain": [
       "Number of examples          : 760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 3</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 3</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients      : 4</pre>"
      ],
      "text/plain": [
       "Number of coefficients      : 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Newton Method</pre>"
      ],
      "text/plain": [
       "Starting Newton Method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Elapsed Time | Training Accuracy | Validation Accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Elapsed Time | Training Accuracy | Validation Accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 1.022994     | 0.936842          | 0.900000            |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 1.022994     | 0.936842          | 0.900000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 1.024689     | 0.936842          | 0.900000            |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 1.024689     | 0.936842          | 0.900000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 1.026314     | 0.935526          | 0.900000            |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 1.026314     | 0.935526          | 0.900000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 1.028111     | 0.934211          | 0.900000            |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 1.028111     | 0.934211          | 0.900000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 6        | 1.029786     | 0.932895          | 0.900000            |</pre>"
      ],
      "text/plain": [
       "| 5         | 6        | 1.029786     | 0.932895          | 0.900000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 7        | 1.031680     | 0.932895          | 0.900000            |</pre>"
      ],
      "text/plain": [
       "| 6         | 7        | 1.031680     | 0.932895          | 0.900000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      "+--------------+-----------------+-------+\n",
      "| target_label | predicted_label | count |\n",
      "+--------------+-----------------+-------+\n",
      "|      0       |        0        |  382  |\n",
      "|      1       |        1        |  363  |\n",
      "|      0       |        1        |   26  |\n",
      "|      1       |        0        |   29  |\n",
      "+--------------+-----------------+-------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "Accuracy: 0.93125\n",
      "Precision: 0.9331619537275064\n",
      "Recall: 0.9260204081632653\n",
      "F[2] Score: 0.9274399591211037\n",
      "Validation Dataset:\n",
      "+--------------+-----------------+-------+\n",
      "| target_label | predicted_label | count |\n",
      "+--------------+-----------------+-------+\n",
      "|      1       |        1        |   56  |\n",
      "|      0       |        0        |   40  |\n",
      "|      1       |        0        |   3   |\n",
      "|      0       |        1        |   1   |\n",
      "+--------------+-----------------+-------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "Accuracy: 0.96\n",
      "Precision: 0.9824561403508771\n",
      "Recall: 0.9491525423728814\n",
      "F[2] Score: 0.9556313993174061\n"
     ]
    }
   ],
   "source": [
    "# 4) Create a perceptron named ‚Äòmodel1‚Äô using Turi Create to classify data with \n",
    "# ‚ÄòCondition‚Äô as the target, with both l1_penalty and l2_penalty set to zero. \n",
    "# Then, for both training and validation data sets:\n",
    "#  ¬∑ Find the predictions using model.predict() and setting output_type=‚Äôclass‚Äô.\n",
    "#  ¬∑ Find and display the confusion matrix using tc.evaluation.confusion_matrix().\n",
    "#  ¬∑ Find and display the accuracy, precision, recall, and ùêπùõΩ score using the value \n",
    "#    of Œ≤ you chose above, and the functions under tc.evaluation.\n",
    "\n",
    "model1 = tc.logistic_classifier.create(train_data, target='Condition', l1_penalty=0, l2_penalty=0)\n",
    "\n",
    "train_predictions = model1.predict(train_data, output_type='class')\n",
    "val_predictions = model1.predict(val_data, output_type='class')\n",
    "\n",
    "# Training Dataset\n",
    "print('Training Dataset:')\n",
    "print(tc.evaluation.confusion_matrix(train_data['Condition'], train_predictions))\n",
    "print('Accuracy:', tc.evaluation.accuracy(train_data['Condition'], train_predictions))\n",
    "print('Precision:', tc.evaluation.precision(train_data['Condition'], train_predictions))\n",
    "print('Recall:', tc.evaluation.recall(train_data['Condition'], train_predictions))\n",
    "print('F[2] Score:', tc.evaluation.fbeta_score(train_data['Condition'], train_predictions, beta=2))\n",
    "\n",
    "# Validation Dataset\n",
    "print('Validation Dataset:')\n",
    "print(tc.evaluation.confusion_matrix(val_data['Condition'], val_predictions))\n",
    "print('Accuracy:', tc.evaluation.accuracy(val_data['Condition'], val_predictions))\n",
    "print('Precision:', tc.evaluation.precision(val_data['Condition'], val_predictions))\n",
    "print('Recall:', tc.evaluation.recall(val_data['Condition'], val_predictions))\n",
    "print('F[2] Score:', tc.evaluation.fbeta_score(val_data['Condition'], val_predictions, beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4900b30-fa1d-4067-95a7-d3b9022eccea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 760</pre>"
      ],
      "text/plain": [
       "Number of examples          : 760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 3</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 3</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients      : 4</pre>"
      ],
      "text/plain": [
       "Number of coefficients      : 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Accelerated Gradient (FISTA)</pre>"
      ],
      "text/plain": [
       "Starting Accelerated Gradient (FISTA)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Tuning step size. First iteration could take longer than subsequent iterations.</pre>"
      ],
      "text/plain": [
       "Tuning step size. First iteration could take longer than subsequent iterations."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 0         | 1        | 1.000000  | 0.000511     | 0.492105          | 0.450000            |</pre>"
      ],
      "text/plain": [
       "| 0         | 1        | 1.000000  | 0.000511     | 0.492105          | 0.450000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 0.002284  | 0.011265     | 0.760526          | 0.825000            |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 0.002284  | 0.011265     | 0.760526          | 0.825000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 0.002284  | 0.013610     | 0.893421          | 0.875000            |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 0.002284  | 0.013610     | 0.893421          | 0.875000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 0.002284  | 0.017059     | 0.913158          | 0.925000            |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 0.002284  | 0.017059     | 0.913158          | 0.925000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 0.002284  | 0.019277     | 0.921053          | 0.900000            |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 0.002284  | 0.019277     | 0.921053          | 0.900000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 6        | 0.002284  | 0.021619     | 0.925000          | 0.900000            |</pre>"
      ],
      "text/plain": [
       "| 5         | 6        | 0.002284  | 0.021619     | 0.925000          | 0.900000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 10        | 11       | 0.002284  | 0.032980     | 0.918421          | 0.925000            |</pre>"
      ],
      "text/plain": [
       "| 10        | 11       | 0.002284  | 0.032980     | 0.918421          | 0.925000            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Completed (Iteration limit reached).</pre>"
      ],
      "text/plain": [
       "Completed (Iteration limit reached)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
      ],
      "text/plain": [
       "This model may not be optimal. To improve it, consider increasing `max_iterations`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      "+--------------+-----------------+-------+\n",
      "| target_label | predicted_label | count |\n",
      "+--------------+-----------------+-------+\n",
      "|      0       |        0        |  378  |\n",
      "|      0       |        1        |   30  |\n",
      "|      1       |        1        |  357  |\n",
      "|      1       |        0        |   35  |\n",
      "+--------------+-----------------+-------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "Accuracy: 0.91875\n",
      "Precision: 0.9224806201550387\n",
      "Recall: 0.9107142857142857\n",
      "F[2] Score: 0.9130434782608694\n",
      "Validation Dataset:\n",
      "+--------------+-----------------+-------+\n",
      "| target_label | predicted_label | count |\n",
      "+--------------+-----------------+-------+\n",
      "|      1       |        1        |   56  |\n",
      "|      0       |        0        |   40  |\n",
      "|      1       |        0        |   3   |\n",
      "|      0       |        1        |   1   |\n",
      "+--------------+-----------------+-------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "Accuracy: 0.96\n",
      "Precision: 0.9824561403508771\n",
      "Recall: 0.9491525423728814\n",
      "F[2] Score: 0.9556313993174061\n"
     ]
    }
   ],
   "source": [
    "# 5) Create a perceptron model named ‚Äòmodel2‚Äô. This time experiment with the l1_penalty \n",
    "# and l2_penalty hyperparameters to see if you can get a better model using regularization. \n",
    "# Then, for both training and validation data sets:\n",
    "#  ¬∑ Find the predictions.\n",
    "#  ¬∑ Find and display the confusion matrix.\n",
    "#  ¬∑ Find and display the accuracy, precision, recall, and ùêπùõΩ score.\n",
    "\n",
    "model2 = tc.logistic_classifier.create(train_data, target='Condition', l1_penalty=20.05, l2_penalty=55.5)\n",
    "\n",
    "train_predictions2 = model2.predict(train_data, output_type='class')\n",
    "val_predictions2 = model2.predict(val_data, output_type='class')\n",
    "\n",
    "# Training Dataset\n",
    "print('Training Dataset:')\n",
    "print(tc.evaluation.confusion_matrix(train_data['Condition'], train_predictions2))\n",
    "print('Accuracy:', tc.evaluation.accuracy(train_data['Condition'], train_predictions2))\n",
    "print('Precision:', tc.evaluation.precision(train_data['Condition'], train_predictions2))\n",
    "print('Recall:', tc.evaluation.recall(train_data['Condition'], train_predictions2))\n",
    "print('F[2] Score:', tc.evaluation.fbeta_score(train_data['Condition'], train_predictions2, beta=2))\n",
    "\n",
    "# Validation Dataset\n",
    "print('Validation Dataset:')\n",
    "print(tc.evaluation.confusion_matrix(val_data['Condition'], val_predictions2))\n",
    "print('Accuracy:', tc.evaluation.accuracy(val_data['Condition'], val_predictions2))\n",
    "print('Precision:', tc.evaluation.precision(val_data['Condition'], val_predictions2))\n",
    "print('Recall:', tc.evaluation.recall(val_data['Condition'], val_predictions2))\n",
    "print('F[2] Score:', tc.evaluation.fbeta_score(val_data['Condition'], val_predictions2, beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58e199f-a728-4887-9c69-b78ca5f28479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Using markdown, select which of your two models is the best (or declare a tie) and \n",
    "# justify your choice by commenting on metrics and the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73395e5-8813-4bec-b80a-9cd1c94ce935",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "<pre>\n",
    "The model I chose is model1. I chose this model for 2 reasons:\n",
    "1. Evaluation metrics: Model1 maintains the highest turicreate evaluation metrics (accuracy, precision, recall, and F2 score) when compared to model2.\n",
    "   Despite experimenting with the l1 and l2 penalties in model2, the metrics do not surpass those of model1.\n",
    "2. Confusion matrix: The second reason is the confusion matrix. Changing the penalties in model2 does not lead to an improvement in the model's performance as seen in the confusion matrix.\n",
    "\n",
    "To summarize, adjusting the penalties doesn't improve model2's performance sufficiently to surpass model1. Therefore, I chose model1 as the best model.\n",
    "</pre>\n",
    "    \n",
    "**Metrics for model1:**\n",
    "<pre>\n",
    "Training Set:                                        Validation Set:\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "| target_label | predicted_label | count |           | target_label | predicted_label | count |\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "|      1       |        1        |  354  |           |      1       |        1        |   56  |\n",
    "|      0       |        0        |  393  |           |      0       |        0        |   40  |\n",
    "|      1       |        0        |   30  |           |      0       |        1        |   3   |\n",
    "|      0       |        1        |   23  |           |      1       |        0        |   1   |\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "\n",
    "- Accuracy: 0.93375                                  - Accuracy: 0.96\n",
    "- Precision: 0.9389920424403183                      - Precision: 0.9491525423728814\n",
    "- Recall: 0.921875                                   - Recall: 0.9824561403508771\n",
    "- F2 Score: 0.9252483010977524                       - F2 Score: 0.975609756097561\n",
    "</pre>\n",
    "    \n",
    "**Metrics for model2 (L1=1.05, L2=2.5):**\n",
    "<pre>\n",
    "Training Set:                                        Validation Set:\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "| target_label | predicted_label | count |           | target_label | predicted_label | count |\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "|      1       |        1        |  351  |           |      1       |        1        |   54  |\n",
    "|      0       |        0        |  396  |           |      0       |        0        |   40  |\n",
    "|      1       |        0        |   33  |           |      0       |        1        |   3   |\n",
    "|      0       |        1        |   20  |           |      1       |        0        |   3   |\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "\n",
    "- Accuracy: 0.93375                                  - Accuracy: 0.94\n",
    "- Precision: 0.9460916442048517                      - Precision: 0.9473684210526315\n",
    "- Recall: 0.9140625                                  - Recall: 0.9473684210526315\n",
    "- F2 Score: 0.9202936549554274                       - F2 Score: 0.9473684210526314\n",
    "</pre>\n",
    "    \n",
    "**Metrics for model2 (L1=100, L2=20):**\n",
    "<pre>\n",
    "Training Set:                                        Validation Set:\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "| target_label | predicted_label | count |           | target_label | predicted_label | count |\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "|      1       |        1        |  341  |           |      1       |        1        |   55  |\n",
    "|      0       |        0        |  396  |           |      0       |        0        |   40  |\n",
    "|      1       |        0        |   43  |           |      0       |        1        |   3   |\n",
    "|      0       |        1        |   20  |           |      1       |        0        |   2   |\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "\n",
    "- Accuracy: 0.92125                                  - Accuracy: 0.95\n",
    "- Precision: 0.9445983379501385                      - Precision: 0.9482758620689655\n",
    "- Recall: 0.8880208333333334                         - Recall: 0.9649122807017544\n",
    "- F2 Score: 0.8987875593041645                       - F2 Score: 0.9615384615384617\n",
    "</pre>\n",
    "    \n",
    "**Metrics for model2 (L1=20, L2=55):**\n",
    "<pre>\n",
    "Training Set:                                        Validation Set:\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "| target_label | predicted_label | count |           | target_label | predicted_label | count |\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "|      1       |        1        |  343  |           |      1       |        1        |   55  |\n",
    "|      0       |        0        |  395  |           |      0       |        0        |   40  |\n",
    "|      1       |        0        |   41  |           |      0       |        1        |   3   |\n",
    "|      0       |        1        |   21  |           |      1       |        0        |   2   |\n",
    "+--------------+-----------------+-------+           +--------------+-----------------+-------+\n",
    "\n",
    "- Accuracy: 0.9225                                   - Accuracy: 0.95\n",
    "- Precision: 0.9423076923076923                      - Precision: 0.9482758620689655\n",
    "- Recall: 0.8932291666666666                         - Recall: 0.9649122807017544\n",
    "- F2 Score: 0.9026315789473682                       - F2 Score: 0.9615384615384617\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b0a706-d0b6-45cb-b4b4-97c8768f6faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Dataset:\n",
      "+--------------+-----------------+-------+\n",
      "| target_label | predicted_label | count |\n",
      "+--------------+-----------------+-------+\n",
      "|      1       |        1        |   46  |\n",
      "|      0       |        0        |   49  |\n",
      "|      0       |        1        |   2   |\n",
      "|      1       |        0        |   3   |\n",
      "+--------------+-----------------+-------+\n",
      "[4 rows x 3 columns]\n",
      "\n",
      "Accuracy: 0.95\n",
      "Precision: 0.9583333333333334\n",
      "Recall: 0.9387755102040817\n",
      "F[2] Score: 0.9426229508196722\n"
     ]
    }
   ],
   "source": [
    "# Using the test set and your choice of best model:\n",
    "#  ¬∑ Find the predictions.\n",
    "#  ¬∑ Find and display the confusion matrix.\n",
    "#  ¬∑ Find and display the accuracy, precision, recall, and ùêπùõΩ score.\n",
    "\n",
    "test_predictions = model1.predict(test_data, output_type='class')\n",
    "\n",
    "# Testing Dataset\n",
    "print('Testing Dataset:')\n",
    "print(tc.evaluation.confusion_matrix(test_data['Condition'], test_predictions))\n",
    "print('Accuracy:', tc.evaluation.accuracy(test_data['Condition'], test_predictions))\n",
    "print('Precision:', tc.evaluation.precision(test_data['Condition'], test_predictions))\n",
    "print('Recall:', tc.evaluation.recall(test_data['Condition'], test_predictions))\n",
    "print('F[2] Score:', tc.evaluation.fbeta_score(test_data['Condition'], test_predictions, beta=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
