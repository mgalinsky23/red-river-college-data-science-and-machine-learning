{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39acbf81-0ce3-4f72-ba7c-dcc194c747ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95637a93-ed49-4ea8-948f-a71dde795241",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[5, 9], [-2, 3], [4, 8], [3, -2], [-3, -7]])\n",
    "y = np.array([16, 1, 14, 21, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679ebf37-5c4a-4d1e-bcb7-f547deaa420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w):\n",
    "    yÃÇ = []\n",
    "    for i in range(len(X)):\n",
    "        pÃÇ = w[0] * X[i][0] + w[1] * X[i][1] + w[2]\n",
    "        yÃÇ.append(pÃÇ)\n",
    "    return yÃÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629d0747-d145-46ab-aa90-c2499ba61cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(w):\n",
    "    yÃÇ = predict(w)\n",
    "    mse = np.mean((y - yÃÇ) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "875b09ee-701f-4b2a-b6ab-6de2c68bc436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(w, ùõø = 0.001):\n",
    "    g = []\n",
    "    loss_0 = loss(w)\n",
    "    for i in range(3):\n",
    "        weights = np.copy(w)\n",
    "        weights[i] += ùõø\n",
    "        loss_1 = loss(weights)\n",
    "        gradient = (loss_1 - loss_0) / ùõø\n",
    "        g.append(gradient)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3434f91a-5078-47fe-9352-c6d37bead321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w, n = 10):\n",
    "    for i in range(3):\n",
    "        w[i] -= n * gradient(w)[i]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f83af2-0990-4da0-9f67-61088c5191bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 11.428035701729321\n",
      "Update Weights: [1.0, -24.04154287978011, 4.979486314733549]\n",
      "New Loss: 155.49198683927918\n"
     ]
    }
   ],
   "source": [
    "#First set of weights\n",
    "w = [1, 1, 1]\n",
    "initial_loss = loss(w)\n",
    "updated_w = update(w)\n",
    "new_loss = loss(updated_w)\n",
    "\n",
    "print(f'Initial Loss: {initial_loss}')\n",
    "print(f'Update Weights: {updated_w}')\n",
    "print(f'New Loss: {new_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7eefca-0709-45d7-aa2e-3af8fb7fa473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 20.33715811021786\n",
      "Updated Weights: [30917.6889837801, -49.455247888341546, -3.941996692446992]\n",
      "New Loss: 109496.16339013436\n"
     ]
    }
   ],
   "source": [
    "#Second set of weights\n",
    "w = [-1, -1, 0]\n",
    "initial_loss = loss(w)\n",
    "updated_w = update(w)\n",
    "new_loss = loss(updated_w)\n",
    "\n",
    "print(f'Initial Loss: {initial_loss}')\n",
    "print(f'Updated Weights: {updated_w}')\n",
    "print(f'New Loss: {new_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa62586-35a7-4c36-ac70-29b97054bb70",
   "metadata": {},
   "source": [
    "# Did the loss get lower after the parameters were updated? Does this mean the code is working properly?\n",
    "\n",
    "**First set of Weights:** \n",
    "- Initial Loss: 11.428\n",
    "- New Loss: 10.850\n",
    "\n",
    "The loss decreased after updating the parameters. This suggests that the code is working properly, as the level of error decreased, indicating that the model is reliable.\n",
    "\n",
    "\n",
    "**Second set of Weights:**\n",
    "- Initial Loss: 20.337\n",
    "- New Loss: 1077.043\n",
    "\n",
    "After updating the parameters, the loss increased significantly. This suggests that the code might not be working correctly, as the level of error increased, which tells us that the model is unreliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aacea9-45d5-402a-93b3-a83959bc85bc",
   "metadata": {},
   "source": [
    "# Did the loss get lower this time? Explain what went wrong and why this is bad.\n",
    "\n",
    "**First set of Weights:**\n",
    "- Initial Loss: 11.428\n",
    "- New Loss: 155.492\n",
    "\n",
    "**Second set of Weights:**\n",
    "- Initial Loss: 20.337\n",
    "- New Loss: 109496.163\n",
    "\n",
    "**Explanation:**\n",
    "The loss increased significantly after setting the learning rate to 10. A higher learning rate can cause the model to overshoot the minimum, leading to higher error values. This is bad because it prevents the model from converging to the optimal solution, making it unreliable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
